{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHbkUPZO9fN4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.dtypes.common import classes\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLYvEQNN9td8",
        "outputId": "87bed4e9-03a2-45f0-98ba-84110bed56ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install split-folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mzVwi819zq6",
        "outputId": "04edab6b-fa6c-4b75-871b-526c89f7a795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "splitfolders.ratio('/content/drive/MyDrive/finaldataset', output=\"char_output_extended\", seed=1337, ratio=(.8, 0.1,0.1)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc6IoFxN95Qx",
        "outputId": "955a5a14-623f-4ed7-f67b-93632277420c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 5518 files [05:05, 18.06 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')"
      ],
      "metadata": {
        "id": "FYyxq50V99Qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "import tensorflow as tf \n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.models import Sequential\n",
        "from six.moves import cPickle as Pickle\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "APkd4akz-dVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_WIDTH=128\n",
        "IMG_HEIGHT=128\n",
        "img_folder=r'/content/char_output_extended/train'"
      ],
      "metadata": {
        "id": "Kq9AacPY-iaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(img_folder):\n",
        "   \n",
        "    img_data_array=[]\n",
        "    class_name=[]\n",
        "   \n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "       \n",
        "            image_path= os.path.join(img_folder, dir1,  file)\n",
        "            image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
        "            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "            image=np.array(image)\n",
        "            image = image.astype('float32')\n",
        "            image /= 255 \n",
        "            img_data_array.append(image)\n",
        "            class_name.append(dir1)\n",
        "    return img_data_array, class_name\n",
        "# extract the image array and class name\n",
        "img_data, class_name =create_dataset(r'/content/char_output_extended/train')"
      ],
      "metadata": {
        "id": "AKDT0hBm-n1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_WIDTH=128\n",
        "IMG_HEIGHT=128\n",
        "img_folder=r'/content/char_output_extended/test'"
      ],
      "metadata": {
        "id": "P28RHtnI-rK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(img_folder):\n",
        "   \n",
        "    img_data_test_array=[]\n",
        "    class_name_test=[]\n",
        "   \n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "       \n",
        "            image_path= os.path.join(img_folder, dir1,  file)\n",
        "            image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
        "            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "            image=np.array(image)\n",
        "            image = image.astype('float32')\n",
        "            image /= 255 \n",
        "            img_data_test_array.append(image)\n",
        "            class_name_test.append(dir1)\n",
        "    return img_data_test_array, class_name_test\n",
        "# extract the image array and class name\n",
        "img_test_data, class_name_test =create_dataset(r'/content/char_output_extended/test')"
      ],
      "metadata": {
        "id": "MLwED3RH-xCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_dict_test={k: v for v, k in enumerate(np.unique(class_name_test))}\n",
        "target_dict_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTfa3_JA-z-b",
        "outputId": "6d64fadc-e27b-4d36-fe2c-e9b0b5aae98c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Aa': 0,\n",
              " 'Aaaa': 1,\n",
              " 'aaha': 2,\n",
              " 'am': 3,\n",
              " 'anna': 4,\n",
              " 'bha': 5,\n",
              " 'cha': 6,\n",
              " 'dha': 7,\n",
              " 'dhaa': 8,\n",
              " 'ee': 9,\n",
              " 'ga': 10,\n",
              " 'ha': 11,\n",
              " 'ja': 12,\n",
              " 'ka': 13,\n",
              " 'la': 14,\n",
              " 'ma': 15,\n",
              " 'na': 16,\n",
              " 'pa': 17,\n",
              " 'ra': 18,\n",
              " 'sya': 19,\n",
              " 'tha': 20,\n",
              " 'va': 21,\n",
              " 'ya': 22,\n",
              " 'yaotthu': 23,\n",
              " 'ye': 24}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_dict={k: v for v, k in enumerate(np.unique(class_name))}\n",
        "target_dict\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCP8Gr1q-4Oz",
        "outputId": "e8a061d6-8736-4f6f-c9e0-cab41e5762d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Aa': 0,\n",
              " 'Aaaa': 1,\n",
              " 'aaha': 2,\n",
              " 'am': 3,\n",
              " 'anna': 4,\n",
              " 'bha': 5,\n",
              " 'cha': 6,\n",
              " 'dha': 7,\n",
              " 'dhaa': 8,\n",
              " 'ee': 9,\n",
              " 'ga': 10,\n",
              " 'ha': 11,\n",
              " 'ja': 12,\n",
              " 'ka': 13,\n",
              " 'la': 14,\n",
              " 'ma': 15,\n",
              " 'na': 16,\n",
              " 'pa': 17,\n",
              " 'ra': 18,\n",
              " 'sya': 19,\n",
              " 'tha': 20,\n",
              " 'va': 21,\n",
              " 'ya': 22,\n",
              " 'yaotthu': 23,\n",
              " 'ye': 24}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_val=  [target_dict[class_name[i]] for i in range(len(class_name))]"
      ],
      "metadata": {
        "id": "0HzrjIk2-7Ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_test_val=  [target_dict_test[class_name_test[i]] for i in range(len(class_name_test))]"
      ],
      "metadata": {
        "id": "cpQG1W98_CDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_WIDTH=128\n",
        "IMG_HEIGHT=128\n",
        "img_folder=r'/content/char_output_extended/val'"
      ],
      "metadata": {
        "id": "iLJaViMI_EX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(img_folder):\n",
        "   \n",
        "    img_data_vali_array=[]\n",
        "    class_name_vali=[]\n",
        "   \n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "       \n",
        "            image_path= os.path.join(img_folder, dir1,  file)\n",
        "            image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
        "            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "            image=np.array(image)\n",
        "            image = image.astype('float32')\n",
        "            image /= 255 \n",
        "            img_data_vali_array.append(image)\n",
        "            class_name_vali.append(dir1)\n",
        "    return img_data_vali_array, class_name_vali\n",
        "# extract the image array and class name\n",
        "img_vali_data, class_name_vali =create_dataset(r'/content/char_output_extended/val')"
      ],
      "metadata": {
        "id": "R3WUd9xy_Itj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_dict_vali={k: v for v, k in enumerate(np.unique(class_name_vali))}\n",
        "target_dict_vali"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s37PvAsX_LdD",
        "outputId": "cd6650a9-1cdd-4d8e-87af-8ae24a991fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Aa': 0,\n",
              " 'Aaaa': 1,\n",
              " 'aaha': 2,\n",
              " 'am': 3,\n",
              " 'anna': 4,\n",
              " 'bha': 5,\n",
              " 'cha': 6,\n",
              " 'dha': 7,\n",
              " 'dhaa': 8,\n",
              " 'ee': 9,\n",
              " 'ga': 10,\n",
              " 'ha': 11,\n",
              " 'ja': 12,\n",
              " 'ka': 13,\n",
              " 'la': 14,\n",
              " 'ma': 15,\n",
              " 'na': 16,\n",
              " 'pa': 17,\n",
              " 'ra': 18,\n",
              " 'sya': 19,\n",
              " 'tha': 20,\n",
              " 'va': 21,\n",
              " 'ya': 22,\n",
              " 'yaotthu': 23,\n",
              " 'ye': 24}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_vali_val=  [target_dict_vali[class_name_vali[i]] for i in range(len(class_name_vali))]"
      ],
      "metadata": {
        "id": "16GwMhCC_Qbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vali_data=np.array(img_vali_data, np.float32)\n",
        "vali_labels=np.array(list(map(int,target_vali_val)), np.float32)\n",
        "vali_labels=to_categorical(vali_labels)\n",
        "print(vali_labels.shape)\n",
        "print(vali_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikFuboJ4_SuD",
        "outputId": "9659125c-77f5-448f-cf47-f99f4dd50ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(539, 25)\n",
            "(539, 128, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "vali_data = np.expand_dims(vali_data[..., 0], axis=-1)\n",
        "print(vali_labels.shape)\n",
        "print(vali_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55z-uoI4_ZXA",
        "outputId": "71c462ca-0691-475b-adec-c27b4258cfcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(539, 25)\n",
            "(539, 128, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Set the directory containing the images\n",
        "data_directory = \"/content/drive/MyDrive/finaldataset\"\n",
        "\n",
        "# Set the number of classes and other hyperparameters\n",
        "num_classes = 25\n",
        "image_size = (128, 128)\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "# Initialize the ImageDataGenerator\n",
        "data_generator = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# Load the training data\n",
        "train_generator = data_generator.flow_from_directory(\n",
        "    data_directory,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load the validation data\n",
        "validation_generator = data_generator.flow_from_directory(\n",
        "    data_directory,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Build the VGG-19 model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (7, 7), activation='relu', padding='same', input_shape=(image_size[0], image_size[1], 3)))\n",
        "model.add(Conv2D(64, (7, 7), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (7, 7), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, (7, 7), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(256, (7, 7), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (7, 7), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (7, 7), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (7, 7), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(512, (7, 7), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (7, 7), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (7, 7), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (7, 7), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(512, (7, 7), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (7, 7), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (7, 7), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (7, 7), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, epochs=epochs, validation_data=validation_generator)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('vgg19_trained_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAgGxDja_2_T",
        "outputId": "c4390f1b-a7e0-474a-b5c5-fa971f459bb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4519 images belonging to 25 classes.\n",
            "Found 1119 images belonging to 25 classes.\n",
            "Epoch 1/10\n",
            "142/142 [==============================] - 151s 884ms/step - loss: 14.7306 - accuracy: 0.0808 - val_loss: 3.0161 - val_accuracy: 0.0965\n",
            "Epoch 2/10\n",
            "142/142 [==============================] - 116s 815ms/step - loss: 3.0271 - accuracy: 0.0894 - val_loss: 3.0119 - val_accuracy: 0.0965\n",
            "Epoch 3/10\n",
            "142/142 [==============================] - 116s 814ms/step - loss: 3.0222 - accuracy: 0.0909 - val_loss: 3.0123 - val_accuracy: 0.0849\n",
            "Epoch 4/10\n",
            "142/142 [==============================] - 116s 816ms/step - loss: 3.0219 - accuracy: 0.0963 - val_loss: 3.0178 - val_accuracy: 0.0965\n",
            "Epoch 5/10\n",
            "142/142 [==============================] - 116s 816ms/step - loss: 3.0242 - accuracy: 0.0934 - val_loss: 3.0115 - val_accuracy: 0.0965\n",
            "Epoch 6/10\n",
            "142/142 [==============================] - 120s 842ms/step - loss: 3.0233 - accuracy: 0.0943 - val_loss: 3.0131 - val_accuracy: 0.0965\n",
            "Epoch 7/10\n",
            "142/142 [==============================] - 116s 813ms/step - loss: 3.0208 - accuracy: 0.0914 - val_loss: 3.0122 - val_accuracy: 0.0965\n",
            "Epoch 8/10\n",
            "142/142 [==============================] - 116s 814ms/step - loss: 3.0210 - accuracy: 0.0929 - val_loss: 3.0105 - val_accuracy: 0.0965\n",
            "Epoch 9/10\n",
            "142/142 [==============================] - 120s 842ms/step - loss: 3.0224 - accuracy: 0.0960 - val_loss: 3.0121 - val_accuracy: 0.0965\n",
            "Epoch 10/10\n",
            "142/142 [==============================] - 120s 842ms/step - loss: 3.0205 - accuracy: 0.0918 - val_loss: 3.0113 - val_accuracy: 0.0831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved VGG-19 model\n",
        "saved_model_path = 'vgg19_trained_model.h5'\n",
        "model = load_model(saved_model_path)\n",
        "\n",
        "# Load and preprocess the image from the test set\n",
        "image_path = '/content/char_output_extended/test/aaha/200.jpg'\n",
        "img = image.load_img(image_path, target_size=(128, 128))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0\n",
        "\n",
        "# Make the prediction\n",
        "prediction = model.predict(img_array)\n",
        "predicted_class = np.argmax(prediction)\n",
        "\n",
        "# Print the predicted class\n",
        "print(\"Predicted Class:\", predicted_class)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e33f86_vLa-G",
        "outputId": "aeab1c04-ca63-4dbc-b747-4e2fc80488a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9a534dd2d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 157ms/step\n",
            "Predicted Class: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = vgg19_trained_model.h5.history['accuracy']\n",
        "val_accuracy  = model_history.history['val_accuracy']\n",
        "\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "I9ExnGRIOFVl",
        "outputId": "8243042e-effe-4742-fa07-0aaa726838d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-e60e347688ec>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg19_trained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_accuracy\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vgg19_trained_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(accuracy, label = \"Training accuracy\")\n",
        "plt.plot(val_accuracy, label=\"Validation accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation accuracy\")\n",
        "\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(loss, label = \"Training loss\")\n",
        "plt.plot(val_loss, label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation loss\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KpKGyKkqOJ3B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}