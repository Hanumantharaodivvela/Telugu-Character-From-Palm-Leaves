{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LH04veg1TNhK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.dtypes.common import classes\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLphTghbTiS_",
        "outputId": "14b9b258-75ec-4ca6-a0fc-6b316c55243d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install split-folders\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly034cPUT0Su",
        "outputId": "c1cd9895-e741-4bc1-ac17-bd89b2c499f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "splitfolders.ratio('/content/drive/MyDrive/finaldataset', output=\"char_output_extended\", seed=1337, ratio=(.8, 0.1,0.1)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3ywxu9TT523",
        "outputId": "4c9061d4-0e20-49b9-b443-3c00e602709b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 5518 files [01:52, 49.23 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')"
      ],
      "metadata": {
        "id": "N10dBRhhUZDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "import tensorflow as tf \n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.models import Sequential\n",
        "from six.moves import cPickle as Pickle\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "FeOimwWNUfoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_WIDTH=224\n",
        "IMG_HEIGHT=224\n",
        "img_folder=r'/content/char_output_extended/train'"
      ],
      "metadata": {
        "id": "hIrAnWt7Uim4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(img_folder):\n",
        "    img_data_test_array = []\n",
        "    class_name_test = []\n",
        "\n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "            image_path = os.path.join(img_folder, dir1, file)\n",
        "            image = cv2.imread(image_path, cv2.COLOR_BGR2RGB)\n",
        "            image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "            image = np.array(image)\n",
        "            image = image.astype('float32')\n",
        "            image /= 255\n",
        "            img_data_test_array.append(image)\n",
        "            class_name_test.append(dir1)\n",
        "\n",
        "    return img_data_test_array, class_name_test\n",
        "\n",
        "# Provide the path to your test image folder\n",
        "img_test_data, class_name_test = create_dataset('/content/char_output_extended/train')"
      ],
      "metadata": {
        "id": "7Qp7BOhYUsEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_WIDTH=224\n",
        "IMG_HEIGHT=224\n",
        "img_folder=r'/content/char_output_extended/test'"
      ],
      "metadata": {
        "id": "Hy6axUJ6UwTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def create_dataset(img_folder):\n",
        "    img_data_test_array = []\n",
        "    class_name_test = []\n",
        "\n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "            image_path = os.path.join(img_folder, dir1, file)\n",
        "            image = cv2.imread(image_path, cv2.COLOR_BGR2RGB)\n",
        "            image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "            image = np.array(image)\n",
        "            image = image.astype('float32')\n",
        "            image /= 255\n",
        "            img_data_test_array.append(image)\n",
        "            class_name_test.append(dir1)\n",
        "\n",
        "    return img_data_test_array, class_name_test\n",
        "\n",
        "# Provide the path to your test image folder\n",
        "img_test_data, class_name_test = create_dataset('/content/char_output_extended/test')\n"
      ],
      "metadata": {
        "id": "pTG98NNdUzXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_dict_test={k: v for v, k in enumerate(np.unique(class_name_test))}\n",
        "target_dict_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6rW5-evVl6E",
        "outputId": "e6cd8c66-1036-4e21-830d-b6e805cbf58f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Aa': 0,\n",
              " 'Aaaa': 1,\n",
              " 'aaha': 2,\n",
              " 'am': 3,\n",
              " 'anna': 4,\n",
              " 'bha': 5,\n",
              " 'cha': 6,\n",
              " 'dha': 7,\n",
              " 'dhaa': 8,\n",
              " 'ee': 9,\n",
              " 'ga': 10,\n",
              " 'ha': 11,\n",
              " 'ja': 12,\n",
              " 'ka': 13,\n",
              " 'la': 14,\n",
              " 'ma': 15,\n",
              " 'na': 16,\n",
              " 'pa': 17,\n",
              " 'ra': 18,\n",
              " 'sya': 19,\n",
              " 'tha': 20,\n",
              " 'va': 21,\n",
              " 'ya': 22,\n",
              " 'yaotthu': 23,\n",
              " 'ye': 24}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_dict={k: v for v, k in enumerate(np.unique(class_name))}\n",
        "target_dict\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PkbJsj3Vqou",
        "outputId": "16ec0e5b-664a-4f3a-9bbf-73008eaa6279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Aa': 0,\n",
              " 'Aaaa': 1,\n",
              " 'aaha': 2,\n",
              " 'am': 3,\n",
              " 'anna': 4,\n",
              " 'bha': 5,\n",
              " 'cha': 6,\n",
              " 'dha': 7,\n",
              " 'dhaa': 8,\n",
              " 'ee': 9,\n",
              " 'ga': 10,\n",
              " 'ha': 11,\n",
              " 'ja': 12,\n",
              " 'ka': 13,\n",
              " 'la': 14,\n",
              " 'ma': 15,\n",
              " 'na': 16,\n",
              " 'pa': 17,\n",
              " 'ra': 18,\n",
              " 'sya': 19,\n",
              " 'tha': 20,\n",
              " 'va': 21,\n",
              " 'ya': 22,\n",
              " 'yaotthu': 23,\n",
              " 'ye': 24}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_val=  [target_dict[class_name[i]] for i in range(len(class_name))]"
      ],
      "metadata": {
        "id": "Q1un-pAIVxXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_test_val=  [target_dict_test[class_name_test[i]] for i in range(len(class_name_test))]"
      ],
      "metadata": {
        "id": "0WuXJrC3VzqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_WIDTH=224\n",
        "IMG_HEIGHT=224\n",
        "img_folder=r'/content/char_output_extended/val'"
      ],
      "metadata": {
        "id": "6fbPp_SgV2HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def create_dataset(img_folder):\n",
        "    img_data_vali_array = []\n",
        "    class_name_vali = []\n",
        "\n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "            image_path = os.path.join(img_folder, dir1, file)\n",
        "            image = cv2.imread(image_path, cv2.COLOR_BGR2RGB)\n",
        "            image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "            image = np.array(image)\n",
        "            image = image.astype('float32')\n",
        "            image /= 255\n",
        "            img_data_vali_array.append(image)\n",
        "            class_name_vali.append(dir1)\n",
        "\n",
        "    return img_data_vali_array, class_name_vali\n",
        "\n",
        "# Provide the path to your validation image folder\n",
        "img_vali_data, class_name_vali = create_dataset('/content/char_output_extended/val')\n"
      ],
      "metadata": {
        "id": "_bU1GFJ4V6sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_dict_vali={k: v for v, k in enumerate(np.unique(class_name_vali))}\n",
        "target_dict_vali"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZFFzIG7V86k",
        "outputId": "89363931-7060-4385-c8b9-cfc9af6813b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Aa': 0,\n",
              " 'Aaaa': 1,\n",
              " 'aaha': 2,\n",
              " 'am': 3,\n",
              " 'anna': 4,\n",
              " 'bha': 5,\n",
              " 'cha': 6,\n",
              " 'dha': 7,\n",
              " 'dhaa': 8,\n",
              " 'ee': 9,\n",
              " 'ga': 10,\n",
              " 'ha': 11,\n",
              " 'ja': 12,\n",
              " 'ka': 13,\n",
              " 'la': 14,\n",
              " 'ma': 15,\n",
              " 'na': 16,\n",
              " 'pa': 17,\n",
              " 'ra': 18,\n",
              " 'sya': 19,\n",
              " 'tha': 20,\n",
              " 'va': 21,\n",
              " 'ya': 22,\n",
              " 'yaotthu': 23,\n",
              " 'ye': 24}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_vali_val=  [target_dict_vali[class_name_vali[i]] for i in range(len(class_name_vali))]"
      ],
      "metadata": {
        "id": "2M8bzgslWXnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vali_data=np.array(img_vali_data, np.float32)\n",
        "vali_labels=np.array(list(map(int,target_vali_val)), np.float32)\n",
        "vali_labels=to_categorical(vali_labels)\n",
        "print(vali_labels.shape)\n",
        "print(vali_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i87Xuok3WZw3",
        "outputId": "7f0d2c72-edb4-46dc-9c35-24ac4100efbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(539, 25)\n",
            "(539, 224, 224)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "vali_data = np.expand_dims(vali_data[..., 0], axis=-1)\n",
        "print(vali_labels.shape)\n",
        "print(vali_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r50DcSb0Wcb6",
        "outputId": "80acfb91-94c1-40d5-bf86-187c3981612d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(539, 25)\n",
            "(539, 224, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.applications.ResNet50(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    **kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "JNX6md4sW5Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "\n",
        "# Set the directory containing the images\n",
        "data_directory = \"/content/drive/MyDrive/finaldataset\"\n",
        "\n",
        "# Set the number of classes and other hyperparameters\n",
        "num_classes = 25\n",
        "image_size = (224, 224)  # Adjusted image size for ResNet-50\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "# Initialize the ImageDataGenerator\n",
        "data_generator = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# Load the training data\n",
        "train_generator = data_generator.flow_from_directory(\n",
        "    data_directory,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load the validation data\n",
        "validation_generator = data_generator.flow_from_directory(\n",
        "    data_directory,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Build the ResNet-50 model\n",
        "model = Sequential()\n",
        "model.add(ResNet50(include_top=False, weights='imagenet', input_shape=image_size + (3,)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, epochs=epochs, validation_data=validation_generator)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('trained_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B87sPbXIW5H6",
        "outputId": "4661e2cb-1149-464d-b17c-ea6809ff87d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4519 images belonging to 25 classes.\n",
            "Found 1119 images belonging to 25 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "142/142 [==============================] - 107s 388ms/step - loss: 1.3121 - accuracy: 0.7670 - val_loss: 3.2224 - val_accuracy: 0.0179\n",
            "Epoch 2/10\n",
            "142/142 [==============================] - 52s 363ms/step - loss: 0.3124 - accuracy: 0.9126 - val_loss: 3.2204 - val_accuracy: 0.0179\n",
            "Epoch 3/10\n",
            "142/142 [==============================] - 51s 360ms/step - loss: 0.2190 - accuracy: 0.9374 - val_loss: 3.2200 - val_accuracy: 0.0179\n",
            "Epoch 4/10\n",
            "142/142 [==============================] - 51s 362ms/step - loss: 0.2329 - accuracy: 0.9378 - val_loss: 3.2204 - val_accuracy: 0.0161\n",
            "Epoch 5/10\n",
            "142/142 [==============================] - 52s 366ms/step - loss: 0.4509 - accuracy: 0.8956 - val_loss: 2.8550 - val_accuracy: 0.2091\n",
            "Epoch 6/10\n",
            "142/142 [==============================] - 51s 360ms/step - loss: 0.2460 - accuracy: 0.9307 - val_loss: 2.7239 - val_accuracy: 0.3146\n",
            "Epoch 7/10\n",
            "142/142 [==============================] - 52s 362ms/step - loss: 0.1167 - accuracy: 0.9642 - val_loss: 0.9706 - val_accuracy: 0.7748\n",
            "Epoch 8/10\n",
            "142/142 [==============================] - 51s 360ms/step - loss: 0.0928 - accuracy: 0.9746 - val_loss: 0.7397 - val_accuracy: 0.8302\n",
            "Epoch 9/10\n",
            "142/142 [==============================] - 51s 361ms/step - loss: 0.0748 - accuracy: 0.9754 - val_loss: 0.4230 - val_accuracy: 0.9240\n",
            "Epoch 10/10\n",
            "142/142 [==============================] - 51s 359ms/step - loss: 0.0625 - accuracy: 0.9816 - val_loss: 0.6918 - val_accuracy: 0.8651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "# Load the saved ResNet-50 model\n",
        "saved_model_path = 'trained_model.h5'\n",
        "model = load_model(saved_model_path)\n",
        "\n",
        "# Load and preprocess the image\n",
        "image_path = '/content/char_output_extended/test/anna/457.jpg'\n",
        "img = image.load_img(image_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = preprocess_input(img_array)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Make the prediction\n",
        "prediction = model.predict(img_array)\n",
        "predicted_class = np.argmax(prediction)\n",
        "\n",
        "# Print the predicted class\n",
        "print(\"Predicted Class:\", predicted_class)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWTNMA4zaOB2",
        "outputId": "6ace3327-7180-4221-9f3b-c0f77d54b170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 930ms/step\n",
            "Predicted Class: 15\n"
          ]
        }
      ]
    }
  ]
}