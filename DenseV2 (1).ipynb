{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKLLpx-gVvgp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.dtypes.common import classes\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU3Dz9v9bDGq",
        "outputId": "ff31d0be-5ed8-4e03-e7a2-0e5d2be93749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install split-folders\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKcIRQ6FbQ0t",
        "outputId": "ac8cd488-3f0d-41c0-b82f-964c6bff41da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "splitfolders.ratio('/content/drive/MyDrive/finaldataset', output=\"char_output_extended\", seed=1337, ratio=(.8, 0.1,0.1)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZmT7LjjbbeL",
        "outputId": "c891dd7e-bae2-41c7-9d2b-ba37933c055c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 5518 files [02:35, 35.58 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')"
      ],
      "metadata": {
        "id": "RQxfbxBgbfbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "import tensorflow as tf \n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.models import Sequential\n",
        "from six.moves import cPickle as Pickle\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "8tGONxsscvYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_WIDTH=224\n",
        "IMG_HEIGHT=224\n",
        "img_folder=r'/content/char_output_extended/train'"
      ],
      "metadata": {
        "id": "iXmv_j9ucyj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(img_folder):\n",
        "   \n",
        "    img_data_array=[]\n",
        "    class_name=[]\n",
        "   \n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "       \n",
        "            image_path= os.path.join(img_folder, dir1,  file)\n",
        "            image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
        "            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "            image=np.array(image)\n",
        "            image = image.astype('float32')\n",
        "            image /= 255 \n",
        "            img_data_array.append(image)\n",
        "            class_name.append(dir1)\n",
        "    return img_data_array, class_name\n",
        "# extract the image array and class name\n",
        "img_data, class_name =create_dataset(r'/content/char_output_extended/train')"
      ],
      "metadata": {
        "id": "ckIIsLh1e8pZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_WIDTH=224\n",
        "IMG_HEIGHT=224\n",
        "img_folder=r'/content/char_output_extended/test'"
      ],
      "metadata": {
        "id": "NKNVoRnPnKBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(img_folder):\n",
        "   \n",
        "    img_data_test_array=[]\n",
        "    class_name_test=[]\n",
        "   \n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "       \n",
        "            image_path= os.path.join(img_folder, dir1,  file)\n",
        "            image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
        "            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "            image=np.array(image)\n",
        "            image = image.astype('float32')\n",
        "            image /= 255 \n",
        "            img_data_test_array.append(image)\n",
        "            class_name_test.append(dir1)\n",
        "    return img_data_test_array, class_name_test\n",
        "# extract the image array and class name\n",
        "img_test_data, class_name_test =create_dataset(r'/content/char_output_extended/test')"
      ],
      "metadata": {
        "id": "NweM2OOOfZ89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_dict_test={k: v for v, k in enumerate(np.unique(class_name_test))}\n",
        "target_dict_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLAMuwaxfb_Y",
        "outputId": "133ba345-8eb6-4432-a60b-bd31c67ae7a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Aa': 0,\n",
              " 'Aaaa': 1,\n",
              " 'aaha': 2,\n",
              " 'am': 3,\n",
              " 'anna': 4,\n",
              " 'bha': 5,\n",
              " 'cha': 6,\n",
              " 'dha': 7,\n",
              " 'dhaa': 8,\n",
              " 'ee': 9,\n",
              " 'ga': 10,\n",
              " 'ha': 11,\n",
              " 'ja': 12,\n",
              " 'ka': 13,\n",
              " 'la': 14,\n",
              " 'ma': 15,\n",
              " 'na': 16,\n",
              " 'pa': 17,\n",
              " 'ra': 18,\n",
              " 'sya': 19,\n",
              " 'tha': 20,\n",
              " 'va': 21,\n",
              " 'ya': 22,\n",
              " 'yaotthu': 23,\n",
              " 'ye': 24}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_dict={k: v for v, k in enumerate(np.unique(class_name))}\n",
        "target_dict\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwBvE8XHff4v",
        "outputId": "b4aa7cfc-0bf3-47db-eebd-df296f4fb00b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Aa': 0,\n",
              " 'Aaaa': 1,\n",
              " 'aaha': 2,\n",
              " 'am': 3,\n",
              " 'anna': 4,\n",
              " 'bha': 5,\n",
              " 'cha': 6,\n",
              " 'dha': 7,\n",
              " 'dhaa': 8,\n",
              " 'ee': 9,\n",
              " 'ga': 10,\n",
              " 'ha': 11,\n",
              " 'ja': 12,\n",
              " 'ka': 13,\n",
              " 'la': 14,\n",
              " 'ma': 15,\n",
              " 'na': 16,\n",
              " 'pa': 17,\n",
              " 'ra': 18,\n",
              " 'sya': 19,\n",
              " 'tha': 20,\n",
              " 'va': 21,\n",
              " 'ya': 22,\n",
              " 'yaotthu': 23,\n",
              " 'ye': 24}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_val=  [target_dict[class_name[i]] for i in range(len(class_name))]"
      ],
      "metadata": {
        "id": "sFnzcsn4fjA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_test_val=  [target_dict_test[class_name_test[i]] for i in range(len(class_name_test))]"
      ],
      "metadata": {
        "id": "8oY3WYtOflfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_WIDTH=224\n",
        "IMG_HEIGHT=224\n",
        "img_folder=r'/content/char_output_extended/val'"
      ],
      "metadata": {
        "id": "FAJcST3ffnfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(img_folder):\n",
        "   \n",
        "    img_data_vali_array=[]\n",
        "    class_name_vali=[]\n",
        "   \n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "       \n",
        "            image_path= os.path.join(img_folder, dir1,  file)\n",
        "            image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
        "            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "            image=np.array(image)\n",
        "            image = image.astype('float32')\n",
        "            image /= 255 \n",
        "            img_data_vali_array.append(image)\n",
        "            class_name_vali.append(dir1)\n",
        "    return img_data_vali_array, class_name_vali\n",
        "# extract the image array and class name\n",
        "img_vali_data, class_name_vali =create_dataset(r'/content/char_output_extended/val')"
      ],
      "metadata": {
        "id": "ujJjBai4f1f9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_dict_vali={k: v for v, k in enumerate(np.unique(class_name_vali))}\n",
        "target_dict_vali"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u_1xFlcf4TE",
        "outputId": "80c0ff7f-8f1c-43e5-baa3-d30a5db4f3b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Aa': 0,\n",
              " 'Aaaa': 1,\n",
              " 'aaha': 2,\n",
              " 'am': 3,\n",
              " 'anna': 4,\n",
              " 'bha': 5,\n",
              " 'cha': 6,\n",
              " 'dha': 7,\n",
              " 'dhaa': 8,\n",
              " 'ee': 9,\n",
              " 'ga': 10,\n",
              " 'ha': 11,\n",
              " 'ja': 12,\n",
              " 'ka': 13,\n",
              " 'la': 14,\n",
              " 'ma': 15,\n",
              " 'na': 16,\n",
              " 'pa': 17,\n",
              " 'ra': 18,\n",
              " 'sya': 19,\n",
              " 'tha': 20,\n",
              " 'va': 21,\n",
              " 'ya': 22,\n",
              " 'yaotthu': 23,\n",
              " 'ye': 24}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_vali_val=  [target_dict_vali[class_name_vali[i]] for i in range(len(class_name_vali))]"
      ],
      "metadata": {
        "id": "IcWOYkdPf6wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vali_data=np.array(img_vali_data, np.float32)\n",
        "vali_labels=np.array(list(map(int,target_vali_val)), np.float32)\n",
        "vali_labels=to_categorical(vali_labels)\n",
        "print(vali_labels.shape)\n",
        "print(vali_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MD_Q_e1f9e_",
        "outputId": "805ff1d8-4b1f-4760-9aeb-d3b5c5f7781b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(539, 25)\n",
            "(539, 224, 224)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "vali_data = np.expand_dims(vali_data[..., 0], axis=-1)\n",
        "print(vali_labels.shape)\n",
        "print(vali_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYO0HuTdf_Cl",
        "outputId": "bdbe11a0-5f27-47cf-8aa2-8b741608c2bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(539, 25)\n",
            "(539, 224, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import DenseNet169\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# Set the directory containing the images\n",
        "data_directory = \"/content/drive/MyDrive/finaldataset\"\n",
        "\n",
        "# Set the number of classes and other hyperparameters\n",
        "num_classes = 25\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "# Initialize the ImageDataGenerator\n",
        "data_generator = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# Load the training data\n",
        "train_generator = data_generator.flow_from_directory(\n",
        "    data_directory,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load the validation data\n",
        "validation_generator = data_generator.flow_from_directory(\n",
        "    data_directory,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Build the DenseNet-169 model\n",
        "base_model = DenseNet169(include_top=False, weights='imagenet', input_shape=(image_size[0], image_size[1], 3))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, epochs=epochs, validation_data=validation_generator)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('densenet169_trained_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIP-3u-xgBP0",
        "outputId": "065f0b41-0230-41fa-de5d-4093dfa6b853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4519 images belonging to 25 classes.\n",
            "Found 1119 images belonging to 25 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "51877672/51877672 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "142/142 [==============================] - 199s 551ms/step - loss: 0.8961 - accuracy: 0.7413 - val_loss: 18.4473 - val_accuracy: 0.1600\n",
            "Epoch 2/10\n",
            "142/142 [==============================] - 65s 457ms/step - loss: 0.3375 - accuracy: 0.8978 - val_loss: 3.2261 - val_accuracy: 0.4665\n",
            "Epoch 3/10\n",
            "142/142 [==============================] - 66s 464ms/step - loss: 0.2466 - accuracy: 0.9283 - val_loss: 0.8899 - val_accuracy: 0.7909\n",
            "Epoch 4/10\n",
            "142/142 [==============================] - 66s 462ms/step - loss: 0.1900 - accuracy: 0.9451 - val_loss: 0.8027 - val_accuracy: 0.7703\n",
            "Epoch 5/10\n",
            "142/142 [==============================] - 65s 456ms/step - loss: 0.2068 - accuracy: 0.9400 - val_loss: 0.7597 - val_accuracy: 0.8222\n",
            "Epoch 6/10\n",
            "142/142 [==============================] - 65s 458ms/step - loss: 0.1415 - accuracy: 0.9611 - val_loss: 1.6976 - val_accuracy: 0.5889\n",
            "Epoch 7/10\n",
            "142/142 [==============================] - 65s 460ms/step - loss: 0.1303 - accuracy: 0.9648 - val_loss: 0.4629 - val_accuracy: 0.8713\n",
            "Epoch 8/10\n",
            "142/142 [==============================] - 64s 454ms/step - loss: 0.1169 - accuracy: 0.9686 - val_loss: 0.3991 - val_accuracy: 0.8963\n",
            "Epoch 9/10\n",
            "142/142 [==============================] - 65s 455ms/step - loss: 0.1533 - accuracy: 0.9564 - val_loss: 1.1936 - val_accuracy: 0.7096\n",
            "Epoch 10/10\n",
            "142/142 [==============================] - 64s 454ms/step - loss: 0.0891 - accuracy: 0.9730 - val_loss: 0.7258 - val_accuracy: 0.8204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "\n",
        "# Load the saved DenseNet-169 model\n",
        "saved_model_path = 'densenet169_trained_model.h5'\n",
        "model = load_model(saved_model_path)\n",
        "\n",
        "# Load and preprocess the image\n",
        "image_path = '/content/char_output_extended/test/yaotthu/220.jpg'\n",
        "img = image.load_img(image_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = preprocess_input(img_array)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Make the prediction\n",
        "prediction = model.predict(img_array)\n",
        "predicted_class = np.argmax(prediction)\n",
        "\n",
        "# Print the predicted class\n",
        "print(\"Predicted Class:\", predicted_class)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZuq0qVZjAQ_",
        "outputId": "818f3dd7-72e9-42b9-91f3-06237e08835d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "Predicted Class: 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Predict the labels for the validation data\n",
        "validation_images, validation_labels = validation_generator.next()\n",
        "y_pred = model.predict(validation_images)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Convert one-hot encoded labels to class indices\n",
        "y_true = np.argmax(validation_labels, axis=1)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "report = classification_report(y_true, y_pred)\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "eqhtyQNrpw2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d456de4e-668c-41d4-ae8c-68fc392c9103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 206ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           3       1.00      1.00      1.00         2\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00         1\n",
            "           7       0.67      0.67      0.67         3\n",
            "           8       0.00      0.00      0.00         1\n",
            "           9       1.00      0.50      0.67         2\n",
            "          11       0.33      1.00      0.50         1\n",
            "          12       0.00      0.00      0.00         1\n",
            "          13       0.67      1.00      0.80         2\n",
            "          15       0.00      0.00      0.00         0\n",
            "          16       1.00      0.50      0.67         2\n",
            "          17       1.00      1.00      1.00         1\n",
            "          18       0.00      0.00      0.00         1\n",
            "          19       0.00      0.00      0.00         0\n",
            "          20       0.00      0.00      0.00         2\n",
            "          21       0.50      1.00      0.67         2\n",
            "          22       1.00      0.80      0.89         5\n",
            "          24       0.67      1.00      0.80         4\n",
            "\n",
            "    accuracy                           0.66        32\n",
            "   macro avg       0.46      0.50      0.46        32\n",
            "weighted avg       0.64      0.66      0.62        32\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Predict the labels for the training data\n",
        "train_images, train_labels = train_generator.next()\n",
        "y_pred_train = model.predict(train_images)\n",
        "y_pred_train = np.argmax(y_pred_train, axis=1)\n",
        "\n",
        "# Convert one-hot encoded labels to class indices\n",
        "y_true_train = np.argmax(train_labels, axis=1)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "report_train = classification_report(y_true_train, y_pred_train)\n",
        "print(report_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nwhp1YtXGCQA",
        "outputId": "b8a0f703-3c6f-40f1-f092-4b3c74dfa6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 136ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      1.00      1.00         1\n",
            "           3       0.50      1.00      0.67         1\n",
            "           4       1.00      1.00      1.00         3\n",
            "           6       0.00      0.00      0.00         2\n",
            "           7       1.00      1.00      1.00         3\n",
            "           8       1.00      1.00      1.00         1\n",
            "          10       1.00      1.00      1.00         2\n",
            "          13       1.00      1.00      1.00         1\n",
            "          14       1.00      1.00      1.00         1\n",
            "          15       1.00      0.50      0.67         2\n",
            "          16       1.00      1.00      1.00         4\n",
            "          17       0.00      0.00      0.00         1\n",
            "          18       1.00      1.00      1.00         1\n",
            "          20       0.00      0.00      0.00         2\n",
            "          21       0.67      1.00      0.80         4\n",
            "          22       1.00      1.00      1.00         2\n",
            "          24       0.25      1.00      0.40         1\n",
            "\n",
            "    accuracy                           0.81        32\n",
            "   macro avg       0.73      0.79      0.74        32\n",
            "weighted avg       0.76      0.81      0.77        32\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate predictions for the validation data\n",
        "validation_generator = data_generator.flow_from_directory(\n",
        "    data_directory,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False  # Ensure consistent ordering of predictions and labels\n",
        ")\n",
        "\n",
        "# Predict the labels for the validation data\n",
        "y_pred = model.predict(validation_generator)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Get the true labels from the validation generator\n",
        "y_true = validation_generator.classes\n",
        "\n",
        "# Get the class labels\n",
        "class_labels = list(validation_generator.class_indices.keys())\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "report = classification_report(y_true, y_pred, target_names=class_labels)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuQpK0MoGhkw",
        "outputId": "34e18a0c-785f-4880-d854-ea7c502562f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1119 images belonging to 25 classes.\n",
            "35/35 [==============================] - 8s 124ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Aa       0.67      0.97      0.79        33\n",
            "        Aaaa       1.00      0.11      0.20        18\n",
            "        aaha       0.96      1.00      0.98        23\n",
            "          am       0.99      0.99      0.99       108\n",
            "        anna       1.00      0.78      0.88        41\n",
            "         bha       0.00      0.00      0.00        10\n",
            "         cha       0.00      0.00      0.00        28\n",
            "         dha       0.89      0.78      0.83        74\n",
            "        dhaa       0.90      0.41      0.56        22\n",
            "          ee       1.00      0.89      0.94        27\n",
            "          ga       0.98      0.93      0.95        43\n",
            "          ha       0.65      1.00      0.78        20\n",
            "          ja       1.00      0.10      0.18        20\n",
            "          ka       0.89      0.97      0.93        32\n",
            "          la       0.79      0.92      0.85        12\n",
            "          ma       0.92      0.71      0.80        86\n",
            "          na       0.95      0.91      0.92        95\n",
            "          pa       0.67      0.57      0.62        14\n",
            "          ra       0.92      0.99      0.95        73\n",
            "         sya       0.45      1.00      0.62        29\n",
            "         tha       1.00      0.69      0.81        70\n",
            "          va       0.70      0.95      0.81        93\n",
            "          ya       1.00      0.78      0.88        55\n",
            "     yaotthu       0.95      0.95      0.95        19\n",
            "          ye       0.54      1.00      0.70        74\n",
            "\n",
            "    accuracy                           0.82      1119\n",
            "   macro avg       0.79      0.74      0.72      1119\n",
            "weighted avg       0.84      0.82      0.80      1119\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cs_l5zpTGzjZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}